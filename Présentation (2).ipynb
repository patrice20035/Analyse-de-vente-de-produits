{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49c0f826-ad6a-4643-bd1a-a23efe89f677",
   "metadata": {},
   "source": [
    "# Web Scraping and price estimation for Carrefour Products and Promotions  \n",
    "## Présentation du projet  \n",
    "**Auteurs** :  \n",
    "- KAMEDA PATRICE THOMAS  \n",
    "- KABORE JULIEN  \n",
    "- MAMADOU GIULIANO  \n",
    "\n",
    "**Date** : 26-04-2025  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bac08c-2506-41c7-915a-b9238cf6ccab",
   "metadata": {},
   "source": [
    "[*LIEN VERS GITHUB*](https://github.com/patrice20035/Analyse-de-vente-de-produits/blob/main/ESTIMATION%20PAR%20FUZZY%20MATCHING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef958ec-3cca-4f91-8db1-85f01f1cbfe2",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Objectif du Projet\n",
    "\n",
    "- Scraper les **produits** et **promotions** Carrefour.\n",
    "- Extraire :\n",
    "  - Prix actuel et ancien prix.\n",
    "  - Promotions et catégories.\n",
    "- Estimer le prix d'un **produit donné** en temps réel.\n",
    "- Exporter les données vers **CSV** et **Excel** avec analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf2f904-50ab-4b4b-9392-1f1fa8564e7a",
   "metadata": {},
   "source": [
    "# Étapes du Programme\n",
    "## 1. Importation des Bibliothèques\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "from rapidfuzz import fuzz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Technologies utilisées\n",
    "\n",
    "- **webdriver** : Contrôle du navigateur Chrome\n",
    "- **Selenium** : Scraping dynamique.\n",
    "- **Pandas** : Manipulation de données.\n",
    "- **RapidFuzz** : Similarité entre noms de produits.\n",
    "- **Matplotlib** : Graphiques.\n",
    "- **Jupyter Notebook** : Développement interactif.\n",
    "- **os** : Gestion des fichiers\n",
    "- **import time** : Délais d'attente pour le chargement des pages\n",
    "- **import re**   Expressions régulières pour nettoyer les prix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db048bfa-0ad3-469c-b642-ca76d80c2af6",
   "metadata": {},
   "source": [
    "## 2. Définition des catégories Carrefour\n",
    "\n",
    "Une liste fixe de 29 catégories est créée pour permettre à l'utilisateur de sélectionner facilement ce qu’il souhaite scraper.\n",
    "\n",
    "```python\n",
    "CATEGORIES = [\n",
    "    'bio-et-ecologie', 'fruits-et-legumes', 'viandes-et-poissons', 'pains-et-patisseries',\n",
    "    'cremerie-et-produits-laitiers', 'charcuterie-et-traiteur', 'surgeles', 'epicerie-salee',\n",
    "    'epicerie-sucree', 'beaute-et-sante', 'boissons', 'nutrition-et-vegetale', 'hygiene-et-beaute',\n",
    "    'entretien-et-nettoyage', 'animalerie', 'bebe', 'jardin', 'entretien-de-la-maison',\n",
    "    'maison-et-decoration', 'cuisine', 'gros-electromenager', 'bricolage',\n",
    "    'velo-trotinettes-et-loisirs', 'smartphones-et-objets-connectes', 'image-et-son',\n",
    "    'informatique-et-bureau', 'jeux-videos', 'jeux-et-jouets', 'mode-et-bagagerie'\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c7b951-b61d-411f-9e55-a5ad5c3d32b9",
   "metadata": {},
   "source": [
    "## 3. Création du dossier de sortie\n",
    "\n",
    "```python\n",
    "OUTPUT_FOLDER = r\"icloud drive/Output\"\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed615d25-b67a-47f8-ace3-ecd241d50f20",
   "metadata": {},
   "source": [
    "## 4. Interactions avec l'utilisateur\n",
    "---\n",
    "### Etape 1. Choix du mode utilisateur\n",
    "\n",
    "À l'exécution, l'utilisateur choisit un des modes suivants :\n",
    "    products : Scraping de produits normaux\n",
    "    promotions : Scraping de promotions\n",
    "    estimate : Estimation de prix par correspondance floue\n",
    "Saisie contrôlée avec validation.\n",
    "\n",
    "    \n",
    "---\n",
    "\n",
    "    \n",
    "### Étape 2 : Définition des catégories Carrefour\n",
    "\n",
    "```python\n",
    "CATEGORIES = ['bio-et-ecologie', 'fruits-et-legumes', ...]\n",
    "```\n",
    "\n",
    "- Liste **prédéfinie** de catégories de produits Carrefour.\n",
    "- Utilisée pour guider le scraping vers les bonnes pages.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "##  Étape 3 : Interaction avec l'utilisateur\n",
    "\n",
    "```python\n",
    "mode = input(\"Souhaitez-vous scraper des promotions, des produits, ou estimer un prix ?\")\n",
    "```\n",
    "\n",
    "- Trois **modes** possibles :\n",
    "  1. **Promotions**.\n",
    "  2. **Produits par catégorie**.\n",
    "  3. **Estimation de prix**.\n",
    "\n",
    "```python\n",
    "mode = input(\"Souhaitez-vous scraper des promotions, des produits, ou estimer un prix ? [promotions/products/estimate] : \").strip().lower()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "    \n",
    "##  Étape 4 : Scraping (cas des promotions)\n",
    "\n",
    "```python\n",
    "def scrap_single_page_promotions():\n",
    "    driver = webdriver.Chrome()  # Lance le navigateur Chrome\n",
    "    page = 0\n",
    "    while True:\n",
    "        driver.get(f\"https://www.carrefour.fr/promotions?page={page}\")\n",
    "```\n",
    "\n",
    "- **Ouvre Chrome** et accède à la page des promotions.\n",
    "- Passe en revue **chaque page** de promotions.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "###  Fonction de scraping\n",
    "\n",
    "**Utilisation de Selenium pour ouvrir plusieurs pages successivement**\n",
    "    Récupération :\n",
    "    **du nom du produit**\n",
    "    **du prix proprement nettoyé**\n",
    "**Sauvegarde temporaire dans un DataFrame**\n",
    "\n",
    "```python\n",
    "def scrap_pages(url_base):\n",
    "    driver = webdriver.Chrome()\n",
    "    all_data = []\n",
    "    for page in range(5):\n",
    "        driver.get(f\"{url_base}&page={page}\")\n",
    "        time.sleep(5)\n",
    "        products = driver.find_elements(By.CLASS_NAME, \"product-list-grid__item\")\n",
    "        print(f\"Scraping page {page + 1} : {len(products)} produits\")\n",
    "\n",
    "        for p in products:\n",
    "            try:\n",
    "                name = p.find_element(By.CSS_SELECTOR, \"a.product-card-title\").text\n",
    "            except:\n",
    "                name = None\n",
    "\n",
    "            try:\n",
    "                price_block = p.find_element(By.CSS_SELECTOR, \"div.product-price__amount--main\")\n",
    "                price_text = price_block.text\n",
    "                clean_price = re.sub(r'[^\\d,\\.]', '', price_text)\n",
    "                price = float(clean_price.replace(',', '.'))\n",
    "            except:\n",
    "                price = None\n",
    "\n",
    "            all_data.append({\n",
    "                \"product_name\": name,\n",
    "                \"price\": price,\n",
    "                \"page\": page + 1\n",
    "            })\n",
    "\n",
    "    driver.quit()\n",
    "    return pd.DataFrame(all_data)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "##  Scraping des informations sur les produits\n",
    "\n",
    "```python\n",
    "name = p.find_element(By.CSS_SELECTOR, \"a.product-card-title\").text\n",
    "price = float(price_text.replace(',', '.'))\n",
    "old_price = float(old_price_text.replace(',', '.'))\n",
    "```\n",
    "\n",
    "- **Nom du produit**.\n",
    "- **Prix actuel** et **ancien prix**.\n",
    "- Nettoyage des prix avec **expressions régulières**.\n",
    "\n",
    "---\n",
    "\n",
    "   \n",
    "### Ajout d'une description de promotion et catégorie\n",
    "\n",
    "```python\n",
    "promo_description = p.find_element(By.CSS_SELECTOR, \"span.promotion-label-refonte__label\").text\n",
    "category = p.find_element(By.CSS_SELECTOR, \"span.product-card-category\").text\n",
    "```\n",
    "\n",
    "- **Description de la promotion**.\n",
    "- **Catégorie du produit** (si disponible).\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "                           \n",
    "## Etape 5 :  Filtrage des produits intéressants\n",
    "\n",
    "```python\n",
    "if (price and old_price and price != old_price) or promo_description:\n",
    "    # Ajouter à la liste des données\n",
    "```\n",
    "\n",
    "- **Conserve** uniquement les produits qui :\n",
    "  - Ont un **prix réduit**.\n",
    "  - Ou une **promotion active**.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "##  Étape 6 : Estimation de prix d’un produit\n",
    "\n",
    "```python\n",
    "def estimate_price():\n",
    "    produit_cible = input(\"Nom du produit à estimer : \")\n",
    "```\n",
    "\n",
    "- **L'utilisateur saisit** un produit.\n",
    "- Scraping de la **catégorie choisie**.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "###  Recherche de produits similaires\n",
    "\n",
    "```python\n",
    "df['similarity'] = df['product_name'].apply(lambda x: produit_cible in x.lower())\n",
    "similaires = df[df['similarity']]\n",
    "```\n",
    "- **Recherche par inclusion** (pas de fuzzy matching ici).\n",
    "- Trouve les **produits similaires** dans la base Carrefour.     *Vérifie si le nom du produit cible est inclus dans les noms du DataFrame*\n",
    "\n",
    " #### Matching des produits similaires\n",
    "\n",
    "**Fuzzy matching avec le catalogue : Compare le nom du produit en promotion avec le catalogue produit. Utilise RapidFuzz pour calculer la similarité (score de 0 à 100).**\n",
    "        **Si similarité > 70%, associe la catégorie.**\n",
    "            \n",
    "```python       \n",
    "            best_match = product_catalog.copy()\n",
    "            best_match['similarity'] = best_match['product_name'].apply(lambda x: fuzz.partial_ratio(name.lower(), x.lower()) if pd.notnull(x) else 0)\n",
    "            best_match = best_match.sort_values(by='similarity', ascending=False).head(1)\n",
    "            category = best_match['category'].values[0] if not best_match.empty and best_match['similarity'].values[0] > 70 else None\n",
    "    \n",
    "    driver.quit()\n",
    "    return pd.DataFrame(all_data)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "#### Analyse des produits similaires\n",
    "\n",
    "```python\n",
    "prix_moyen = similaires['price'].mean()\n",
    "prix_min = similaires['price'].min()\n",
    "prix_max = similaires['price'].max()\n",
    "```\n",
    "\n",
    "- Affiche :\n",
    "  - **Prix moyen**.\n",
    "  - **Prix minimum**.\n",
    "  - **Prix maximum**.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "##  Étape 7 : Exportation des résultats\n",
    "\n",
    "```python\n",
    "df.to_csv(csv_path)\n",
    "with pd.ExcelWriter(excel_path) as writer:\n",
    "    df.to_excel(writer, sheet_name='Données')\n",
    "```\n",
    "\n",
    "- **CSV** pour les données brutes.\n",
    "- **Excel** avec :\n",
    "  - **Données brutes**.\n",
    "  - **Analyses** (moyenne des réductions, nombre de promotions par catégorie).\n",
    "\n",
    "---\n",
    "##  Conclusion sur les  Fonctionnalités\n",
    "\n",
    "\n",
    "1. **Scraping des promotions** (multi-pages).\n",
    "2. **Scraping des produits** par catégorie.\n",
    "3. **Estimation de prix** basée sur le nom d'un produit.\n",
    "4. **Analyses automatiques** :\n",
    "   - Produits ayant les plus grandes réductions\n",
    "   -Prix min et max des produits entrés\n",
    "5. **Exportation** :\n",
    "   - CSV.\n",
    "   - Excel (analyses incluses).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30497c6-0a0e-4560-a20f-d4b8e52e80b8",
   "metadata": {},
   "source": [
    "#  Perspectives d'Amélioration\n",
    "\n",
    "**-Optimiser le matching par d'autres méthodes (embedding NLP)**.\n",
    "\n",
    "**-Intégrer une interface utilisateur graphique (GUI).**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040e9373-a4f7-4e76-aca5-f1d91c0e5494",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
